{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "data = []\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def create_dataset(dataset, look_back=12):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        aux = dataset[i:(i+look_back)]\n",
    "        dataX.append(aux)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "with open('./datasets/traffic-prediction-dataset.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        row_to_append = [float(x) for x in row[0:4]]\n",
    "        data.append(row_to_append)\n",
    "\n",
    "scaler.fit(data)\n",
    "normalized_data = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(normalized_data) * 0.75)\n",
    "test_size = len(normalized_data) - train_size\n",
    "\n",
    "train, test = normalized_data[0:train_size,:], normalized_data[train_size:len(normalized_data),:]\n",
    "x_train, y_train = create_dataset(train)\n",
    "x_test, y_test = create_dataset(test)\n",
    "y_real = scaler.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rnn_size = int(len(x_train)*0.95)\n",
    "\n",
    "x_train_rnn, y_train_rnn = x_train[0:train_rnn_size,:], y_train[0:train_rnn_size,:]\n",
    "x_val_rnn, y_val_rnn = x_train[train_rnn_size:len(x_train),:], y_train[train_rnn_size:len(y_train),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LSTM-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 12, 64)            17664     \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,948\n",
      "Trainable params: 50,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "90/90 [==============================] - 4s 24ms/step - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 2s 20ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 2s 19ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 2s 23ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 2s 23ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0019 - val_loss: 0.0018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7092c6df0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout, InputLayer\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(InputLayer(input_shape=(12, 4)))\n",
    "lstm_model.add(LSTM(64, return_sequences=True))\n",
    "lstm_model.add(LSTM(64))\n",
    "lstm_model.add(Dropout(0.2))\n",
    "lstm_model.add(Dense(4))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "lstm_model.summary()\n",
    "\n",
    "lstm_model.fit(x_train_rnn, y_train_rnn, epochs=50, batch_size=128, validation_data=(x_val_rnn, y_val_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing LSTM-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 5ms/step\n",
      "Mean Absolute error: 10.825328745745061\n",
      "Mean Absolute Percentage error: 921925219624300.1\n",
      "Mean Squared error: 15.833685012283713\n",
      "R-Squared score: 0.9300004819342713\n",
      "Explained Variance score: 0.9307716447480484\n"
     ]
    }
   ],
   "source": [
    "y_pred_lstm = lstm_model.predict(x_test)\n",
    "\n",
    "y_real_pred_lstm = scaler.inverse_transform(y_pred_lstm)\n",
    " \n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_lstm))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_lstm))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_lstm, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_lstm))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training GRU-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_2 (GRU)                 (None, 12, 64)            13440     \n",
      "                                                                 \n",
      " gru_3 (GRU)                 (None, 64)                24960     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,660\n",
      "Trainable params: 38,660\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "90/90 [==============================] - 4s 22ms/step - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 2/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 3/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 4/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 5/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 6/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 7/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 8/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 9/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 10/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 11/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 12/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 13/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 14/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 15/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 16/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 17/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 20/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 22/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 23/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 25/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 26/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 27/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 28/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 30/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 32/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 33/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 35/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 36/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 40/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 41/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 43/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 44/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 45/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 46/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 47/50\n",
      "90/90 [==============================] - 2s 18ms/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 48/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 49/50\n",
      "90/90 [==============================] - 2s 17ms/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 50/50\n",
      "90/90 [==============================] - 1s 16ms/step - loss: 0.0020 - val_loss: 0.0019\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6ffea4e80>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import GRU\n",
    "\n",
    "gru_model = Sequential()\n",
    "gru_model.add(InputLayer(input_shape=(12, 4)))\n",
    "gru_model.add(GRU(64, return_sequences=True))\n",
    "gru_model.add(GRU(64))\n",
    "gru_model.add(Dropout(0.2))\n",
    "gru_model.add(Dense(4))\n",
    "gru_model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "gru_model.summary()\n",
    "\n",
    "gru_model.fit(x_train_rnn, y_train_rnn, epochs=50, batch_size=128, validation_data=(x_val_rnn, y_val_rnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing GRU-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 5ms/step\n",
      "Mean Absolute error: 11.280484681992121\n",
      "Mean Absolute Percentage error: 1563710217145945.0\n",
      "Mean Squared error: 16.333450336774902\n",
      "R-Squared score: 0.9251373812182374\n",
      "Explained Variance score: 0.9270541875009984\n"
     ]
    }
   ],
   "source": [
    "y_pred_gru = gru_model.predict(x_test)\n",
    "\n",
    "y_real_pred_gru = scaler.inverse_transform(y_pred_gru)\n",
    " \n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_gru))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_gru))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_gru, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_gru))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_gru))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array3dto2d(array):\n",
    "    return array.reshape(array.shape[0], (array.shape[1]*array.shape[2]))\n",
    "\n",
    "x_train2d = array3dto2d(x_train)\n",
    "x_test2d = array3dto2d(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error: 10.995112992690943\n",
      "Mean Absolute Percentage error: 1215443375208624.8\n",
      "Mean Squared error: 15.964060260773927\n",
      "R-Squared score: 0.9287586530693062\n",
      "Explained Variance score: 0.9292343641817418\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear_regression_model = LinearRegression().fit(x_train2d, y_train)\n",
    "linear_regression_prediction = linear_regression_model.predict(x_test2d)\n",
    "\n",
    "y_real_pred_lr = scaler.inverse_transform(linear_regression_prediction)\n",
    "\n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_lr))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_lr))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_lr, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_lr))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error: 11.017974318566079\n",
      "Mean Absolute Percentage error: 741872148482966.4\n",
      "Mean Squared error: 16.329491974927954\n",
      "R-Squared score: 0.9260844119027556\n",
      "Explained Variance score: 0.9266281566391708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "gradient_boosting_regressor_model = MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(x_train2d, y_train)\n",
    "gradient_boosting_regressor_prediction = gradient_boosting_regressor_model.predict(x_test2d)\n",
    "\n",
    "y_real_pred_gbr = scaler.inverse_transform(gradient_boosting_regressor_prediction)\n",
    "\n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_gbr))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_gbr))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_gbr, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_gbr))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MultiLayer Perceptron Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error: 11.364891533088883\n",
      "Mean Absolute Percentage error: 1517729348770284.0\n",
      "Mean Squared error: 16.406624394242687\n",
      "R-Squared score: 0.9238183799802224\n",
      "Explained Variance score: 0.9258635803959911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_regressor_model = MLPRegressor(random_state=0).fit(x_train2d, y_train)\n",
    "mlp_regressor_prediction = mlp_regressor_model.predict(x_test2d)\n",
    "\n",
    "y_real_pred_mlpr = scaler.inverse_transform(mlp_regressor_prediction)\n",
    "\n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_mlpr))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_mlpr))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_mlpr, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_mlpr))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_mlpr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descendent Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error: 12.187349624612459\n",
      "Mean Absolute Percentage error: 2803388624268320.0\n",
      "Mean Squared error: 17.980527117240715\n",
      "R-Squared score: 0.9068198160471619\n",
      "Explained Variance score: 0.9110625297566236\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "sgd_regressor_model = MultiOutputRegressor(SGDRegressor(random_state=0)).fit(x_train2d, y_train)\n",
    "sgd_regressor_prediction = sgd_regressor_model.predict(x_test2d)\n",
    "\n",
    "y_real_pred_sgdr = scaler.inverse_transform(sgd_regressor_prediction)\n",
    "\n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_sgdr))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_sgdr))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_sgdr, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_sgdr))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_sgdr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute error: 12.28977345857269\n",
      "Mean Absolute Percentage error: 3937009837481399.0\n",
      "Mean Squared error: 19.080446960903608\n",
      "R-Squared score: 0.8865108967363967\n",
      "Explained Variance score: 0.8889978198000288\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "random_forest_regressor_model = RandomForestRegressor(random_state=0).fit(x_train2d, y_train)\n",
    "random_forest_regressor_prediction = random_forest_regressor_model.predict(x_test2d)\n",
    "\n",
    "y_real_pred_rfr = scaler.inverse_transform(random_forest_regressor_prediction)\n",
    "\n",
    "print(\"Mean Absolute error:\", mean_absolute_error(y_real, y_real_pred_rfr))\n",
    "print(\"Mean Absolute Percentage error:\", mean_absolute_percentage_error(y_real, y_real_pred_rfr))\n",
    "print(\"Mean Squared error:\", mean_squared_error(y_real, y_real_pred_rfr, squared=False))\n",
    "print(\"R-Squared score:\", r2_score(y_real, y_real_pred_rfr))\n",
    "print(\"Explained Variance score:\", explained_variance_score(y_real, y_real_pred_rfr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e1003431ffaf7ede86a3f1a398312c7d1bbb13de8cad98e0a1dc871d27342b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
