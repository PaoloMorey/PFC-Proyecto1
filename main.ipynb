{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paolo/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.29787234, 0.1589404 , 0.13761468, 0.19871795],\n",
       "       [0.2751773 , 0.13576159, 0.14678899, 0.17628205],\n",
       "       [0.21560284, 0.15562914, 0.20183486, 0.18589744],\n",
       "       ...,\n",
       "       [0.23546099, 0.11258278, 0.1559633 , 0.19551282],\n",
       "       [0.25248227, 0.12913907, 0.1146789 , 0.15384615],\n",
       "       [0.18723404, 0.1192053 , 0.11926606, 0.16025641]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = []\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "def create_dataset(dataset, look_back=12):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        aux = dataset[i:(i+look_back)]\n",
    "        dataX.append(aux)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "with open('./datasets/traffic-prediction-dataset.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for row in csv_reader:\n",
    "        row_to_append = [float(x) for x in row[0:4]]\n",
    "        data.append(row_to_append)\n",
    "\n",
    "scaler.fit(data)\n",
    "normalized_data = scaler.transform(data)\n",
    "                \n",
    "normalized_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12083, 12, 4)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(len(normalized_data) * 0.75)\n",
    "test_size = len(normalized_data) - train_size\n",
    "\n",
    "train, test = normalized_data[0:train_size,:], normalized_data[train_size:len(normalized_data),:]\n",
    "x_train, y_train = create_dataset(train)\n",
    "x_test, y_test = create_dataset(test)\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-17 21:48:12.439359: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-17 21:48:12.604748: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-10-17 21:48:12.611327: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-17 21:48:12.611343: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-17 21:48:12.648096: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-17 21:48:13.391730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-17 21:48:13.391802: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-17 21:48:13.391810: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-17 21:48:15.567407: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-10-17 21:48:15.567457: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: paolo-Pulse-GL66-11UGKV\n",
      "2022-10-17 21:48:15.567465: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: paolo-Pulse-GL66-11UGKV\n",
      "2022-10-17 21:48:15.567635: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.76.0\n",
      "2022-10-17 21:48:15.567665: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: NOT_FOUND: could not find kernel module information in driver version file contents: \"NVRM version: NVIDIA UNIX Open Kernel Module for x86_64  515.76  Release Build  (dvs-builder@U16-T02-3-3)  Mon Sep 12 19:20:55 UTC 2022\n",
      "GCC version:  gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) \n",
      "\"\n",
      "2022-10-17 21:48:15.568215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 12, 64)            17664     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,948\n",
      "Trainable params: 50,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "95/95 [==============================] - 5s 16ms/step - loss: 0.0091\n",
      "Epoch 2/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0047\n",
      "Epoch 3/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0038\n",
      "Epoch 4/50\n",
      "95/95 [==============================] - 1s 16ms/step - loss: 0.0032\n",
      "Epoch 5/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0029\n",
      "Epoch 6/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0028\n",
      "Epoch 7/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0026\n",
      "Epoch 8/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0026\n",
      "Epoch 9/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0024\n",
      "Epoch 10/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0024\n",
      "Epoch 11/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0023\n",
      "Epoch 12/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0023\n",
      "Epoch 13/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.0023\n",
      "Epoch 14/50\n",
      "95/95 [==============================] - 2s 19ms/step - loss: 0.0022\n",
      "Epoch 15/50\n",
      "95/95 [==============================] - 2s 19ms/step - loss: 0.0022\n",
      "Epoch 16/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.0022\n",
      "Epoch 17/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0022\n",
      "Epoch 18/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0021\n",
      "Epoch 19/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0022\n",
      "Epoch 20/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0021\n",
      "Epoch 21/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0021\n",
      "Epoch 22/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0021\n",
      "Epoch 23/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0021\n",
      "Epoch 24/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0021\n",
      "Epoch 25/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0021\n",
      "Epoch 26/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0021\n",
      "Epoch 27/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0021\n",
      "Epoch 28/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0021\n",
      "Epoch 29/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0021\n",
      "Epoch 30/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 31/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0021\n",
      "Epoch 32/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 33/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 34/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.0020\n",
      "Epoch 35/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 36/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 37/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 38/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 39/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 40/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 41/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 42/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 43/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 44/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 45/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 46/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n",
      "Epoch 47/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 48/50\n",
      "95/95 [==============================] - 2s 16ms/step - loss: 0.0020\n",
      "Epoch 49/50\n",
      "95/95 [==============================] - 2s 18ms/step - loss: 0.0020\n",
      "Epoch 50/50\n",
      "95/95 [==============================] - 2s 17ms/step - loss: 0.0020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f069c3dba90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras import Input\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(12, 4)))\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(12, 4)))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(4))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126/126 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.09067962, 0.03969803, 0.06927239, 0.06536179],\n",
       "       [0.08943988, 0.03405983, 0.06021421, 0.05097923],\n",
       "       [0.10608035, 0.0367779 , 0.06870245, 0.05145346],\n",
       "       ...,\n",
       "       [0.22340705, 0.11582818, 0.16798273, 0.18116175],\n",
       "       [0.20923865, 0.12448627, 0.16822943, 0.16662633],\n",
       "       [0.21829917, 0.12371694, 0.1596344 , 0.16696627]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.939831443013253"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "final_y_real = scaler.inverse_transform(y_test)\n",
    "final_y_pred = scaler.inverse_transform(y_pred)\n",
    "mean_absolute_error(final_y_real, final_y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e1003431ffaf7ede86a3f1a398312c7d1bbb13de8cad98e0a1dc871d27342b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
